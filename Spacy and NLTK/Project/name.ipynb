{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializer\n",
    "\n",
    "* -hu how are you?\n",
    "* -hd how is your day?\n",
    "\n",
    "* An adverb is a part of speech used to describe a verb, adjective, clause, or another adverb. It simply tells the readers how, where, when, or the degree at which something was done. Examples: The manager accepted the challenge very nicely. The manager accepted the challenge very nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    { \"tag\":\"hi\", \"pattern\": [ 'hi', 'hello', 'yo','hey','greetings','good morning','evening',\"sup\",'afternoon' ], \n",
    "     \"response\":['Hi, how is your day? -hd', 'Hello, how are you? -hu'], \"state\": False},\n",
    "    {\"tag\": \"state_of_being\",\"pattern\": [\"hi,How are you?\", \"how are you\", \"Whats up\", \"how are you doing this morning?\", \"doing this afternoon?\", \"this evening?\", \"how far?\", \"this morning\", \"doing this evening?\"], \n",
    "     \"response\": [], \"state\": False},\n",
    "    {\"tag\": \"name\",\"pattern\": [\"What is your name?\", \"can I know you\", \"your name please\",\"what should I call you\", \"who are you\", \"what are you called?\", \"can I know your name\", \"please I wish to know your name?\"],\n",
    "     \"response\": [], 'state': False},\n",
    "    {\"tag\": \"create_you\",\"pattern\": [\"who created you\", \"who made you\", \"who built you\", \"who developed you\", \"who is your founder\"],\n",
    "     \"responses\": [\"I was made by a team at AppsTechLabs\", \"I was made by a team of people, at AppsTechLabs\", \"A team at AppsTechLabs made me what I am today, the are sort of like my family, they always ensure I bring more value to you. trying saying, help, to see a list of what I can do\"],\n",
    "    \"state\": False},\n",
    "    {\"tag\": \"owner\", \"pattern\": [\"who is your owner\", \"woner\", \"who owns you\"],\"responses\": [\"I think I'm yours\", \"I'm yours\", \"guess that would be you\", \"I'm pretty sure that would be you\"],\"state\": False},\n",
    "    {\"tag\": \"know me\",\"pattern\": [\"do you know me?\", \"do you know my name?\"],\"responses\": [\"Sorry that I don't know you for now, but trust me it won't be long. (:-\"], \"state\": False},\n",
    "    {\"tag\": \"age\", \"pattern\": [\"how old are you\",\" whats your age\",\"tell me your age\",\"can I know how old you are?\",\"can I know your age\"], \n",
    "     \"responses\": [\"I don't age, but I was made by a team at AppsTechLabs. They made me what I am today.\"],'state': False},\n",
    "    {\"tag\": \"creator\",\"pattern\": [\"what's your creator name\", \"who is your creator\", \"whats your creator name\", \"what is your creator name\", \"creator\", \"who program you\"],\n",
    "    \"responses\": [\"At first, I was just an idea, then a bunch of people at AppsTechLabs put their heads together, And now, here I am\", \"Everyone at AppsTechLabs is sort of like my family, they made me what I am today\",\n",
    "                                \"I consider everyone at AppsTechLabs to be my family, it's a lot of birthdays to remember, but I like it\",\n",
    "                                \"The AppsTechLabs team is like my family, they mean a lot to me\",\n",
    "                                \"AppsTechLabs is my family\"], 'state': False }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-Base Matching And Spell Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'upper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-88e6c86a78ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msay_hi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-88e6c86a78ed>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmake_uppercase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_uppercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'upper'"
     ]
    }
   ],
   "source": [
    "def uppercase_decorator(function):\n",
    "    def wrapper():\n",
    "        func = function()\n",
    "        make_uppercase = func.upper()\n",
    "        return make_uppercase\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def split_string(function):\n",
    "    def wrapper():\n",
    "        func = function()\n",
    "        splitted_string = func.split()\n",
    "        return splitted_string\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def say_hi():\n",
    "    return 'hello there'\n",
    "\n",
    "\n",
    "print(say_hi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "m_tool = Matcher(sp.vocab)\n",
    "\n",
    "\n",
    "# Patterns\n",
    "hi_hu = [{\"LOWER\": \"-hu\"}]\n",
    "hi_hd = [{\"LOWER\": '-hd'}]\n",
    "\n",
    "# Add patterns to matcher object\n",
    "m_tool.add('HI', None, hi_hd, hi_hu)\n",
    "\n",
    "# 1\n",
    "def matcher(sent):\n",
    "    sentence = sp(sent)\n",
    "    phrase_match = m_tool(sentence)\n",
    "    \n",
    "    for match_id, start, end in phrase_match:\n",
    "        string_id = sp.vocab.strings[match_id]\n",
    "        span = sentence[start: end]\n",
    "        \n",
    "        return string_id, span.text, sent.replace(f' {span.text}', '')\n",
    "# 3\n",
    "def Hi(arg):\n",
    "    if len(arg) == 4:\n",
    "        tag, pattern, model_res, user_res = arg\n",
    "        data = {'tag':tag, 'pattern': pattern, 'model_res': model_res, 'user_res': user_res}\n",
    "        return data\n",
    "    \n",
    "    elif len(arg) == 3:\n",
    "        tag, pattern, model_res = arg\n",
    "        data = {'tag':tag, 'pattern': pattern, 'model_res': model_res, 'user_res': ''}\n",
    "        return data\n",
    "# 2\n",
    "def tag_matcher(sent):\n",
    "    arg = matcher(sent)\n",
    "    tag, pattern, model_res = arg\n",
    "    \n",
    "    selector = {\n",
    "        \"HI\": Hi\n",
    "    }\n",
    "    \n",
    "    return selector.get(tag)([tag,pattern,model_res])\n",
    "\n",
    "def how_are_you(sent):\n",
    "    sentence = nltk.word_tokenize(sent)\n",
    "    sentence = nltk.pos_tag(sentence)\n",
    "    sent_in_pos = ''\n",
    "    \n",
    "    for word in sentence:\n",
    "        sent_in_pos += word[1] + ' '\n",
    "    if 'JJ CC PRP' in sent_in_pos or 'CC PRP' in sent_in_pos:\n",
    "        res = [ tag for tag in sentence if \"JJ\" in tag[1]]\n",
    "        print(sent, sent_in_pos)\n",
    "        return True, res[0]\n",
    "    elif 'JJ' in sent_in_pos or 'NN' in sent_in_pos:\n",
    "        res = [ tag for tag in sentence if \"JJ\" in tag[1] or \"NN\" in tag[1]]\n",
    "        return False, res[0]\n",
    "        \n",
    "\n",
    "def pos_tag(sent):\n",
    "    text_blob_object = TextBlob(sent).correct()\n",
    "    state, res = how_are_you(str(text_blob_object))\n",
    "#     print(res, state)\n",
    "    if state:\n",
    "        if text_blob_object.sentiment.polarity > 0:\n",
    "            res = f\"Bot: I'm glad you are {res[0]}. \\nBot: As for me, I'm awesome. Thanks for asking. \\nBot: Please I wish to know your name.\"\n",
    "            return 'Pos', res\n",
    "        else:\n",
    "            res = f\"Bot: I'm sorry about that, is there anything I can do to make you smile?\"\n",
    "            return 'Neg',res\n",
    "    else:\n",
    "        if text_blob_object.sentiment.polarity > 0:\n",
    "            res = f\"Bot: I'm glad you are {res[0]}. \\nBot: What's on your mind for today?\"\n",
    "            return 'Pos', res\n",
    "        else:\n",
    "            res = f\"Bot: I'm sorry about that, is there anything I can do to make you smile?\"\n",
    "            return 'Neg',res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pos', \"Bot: I'm glad you are awesome. \\nBot: What's on your mind for today?\")\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag(\"I am not too awesome\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('following', 'VBG')\n",
      "('day', 'NN')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = nltk.word_tokenize(\"following day\")\n",
    "hey = nltk.pos_tag(text)\n",
    "for me in hey:\n",
    "    print(me)\n",
    "    if me[1] in ('JJ', 'CC'):\n",
    "        print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('set', 'VB')\n",
      "('an', 'DT')\n",
      "('event', 'NN')\n",
      "\n",
      "('set', 'VBN')\n",
      "('up', 'RP')\n",
      "('an', 'DT')\n",
      "('event', 'NN')\n",
      "\n",
      "('book', 'NN')\n",
      "('an', 'DT')\n",
      "('event', 'NN')\n",
      "\n",
      "('book', 'NN')\n",
      "('event', 'NN')\n",
      "\n",
      "('hook', 'NN')\n",
      "('an', 'DT')\n",
      "('event', 'NN')\n",
      "\n",
      "('hook', 'VB')\n",
      "('up', 'RP')\n",
      "('an', 'DT')\n",
      "('event', 'NN')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "h = ['set an event', 'set up an event', 'book an event', 'book event','hook an event',\n",
    "    'hook up an event']\n",
    "for sen in h:\n",
    "    text = nltk.word_tokenize(sen)\n",
    "    hey = nltk.pos_tag(text)\n",
    "    print()\n",
    "    for me in hey:\n",
    "        print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "set          VERB       VB       verb, base form\n",
      "an           DET        DT       determiner\n",
      "event        NOUN       NN       noun, singular or mass\n",
      "\n",
      "set          VERB       VB       verb, base form\n",
      "up           ADP        RP       adverb, particle\n",
      "an           DET        DT       determiner\n",
      "event        NOUN       NN       noun, singular or mass\n",
      "\n",
      "book         PROPN      NNP      noun, proper singular\n",
      "an           DET        DT       determiner\n",
      "event        NOUN       NN       noun, singular or mass\n",
      "\n",
      "book         NOUN       NN       noun, singular or mass\n",
      "event        NOUN       NN       noun, singular or mass\n",
      "\n",
      "hook         VERB       VB       verb, base form\n",
      "an           DET        DT       determiner\n",
      "event        NOUN       NN       noun, singular or mass\n",
      "\n",
      "hook         VERB       VB       verb, base form\n",
      "up           ADP        RP       adverb, particle\n",
      "an           DET        DT       determiner\n",
      "event        NOUN       NN       noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "h = ['set an event', 'set up an event', 'book an event', 'book event', 'hook an event',\n",
    "    'hook up an event']\n",
    "for letter in h:\n",
    "    sen = sp(letter)\n",
    "    print()\n",
    "    for word in sen:\n",
    "        print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:30pm - CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "sens = sp(\"9:30pm is the time is \")\n",
    "h =  [ (ent.label_, ent.text) for ent in sens.ents if ent.label_ is 'DATE' or ent.label_ is 'TIME']\n",
    "if len(h) is not 0:\n",
    "    for ent in h:\n",
    "        print(ent[0])\n",
    "\n",
    "for entity in sens.ents:\n",
    "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "PM 4 pm 4\n"
     ]
    }
   ],
   "source": [
    "message = \"set up and event the following day by 4 pm in the evening\"\n",
    "\n",
    "def event_date(message):\n",
    "    sentence = sp(message)\n",
    "    sentence = [ (ent.label_, ent.text) for ent in sentence.ents if ent.label_ is 'DATE' or ent.label_ is 'TIME']\n",
    "    \n",
    "    if len(sentence) is not 0:\n",
    "        for ent in sentence:\n",
    "            if ent[0] in 'DATE':\n",
    "                date = ent[1]\n",
    "                num = ''.join([i for i in date if i.isdigit()])\n",
    "                if num:\n",
    "                    print(next_some_days(int(num)))\n",
    "                else:\n",
    "                    time = {\n",
    "                        'today': today,\n",
    "                        'tomorrow': tomorrow\n",
    "                    }\n",
    "                    \n",
    "                    print(time.get(date))\n",
    "            elif ent[0] in 'TIME':\n",
    "                time = ent[1]\n",
    "                num = ''.join([i for i in time if i.isdigit()])\n",
    "                if 'am' in time.lower() :\n",
    "                    print(\"AM\", time, num)\n",
    "                elif 'pm' in time.lower():\n",
    "                    print('PM', time, num)\n",
    "                \n",
    "                \n",
    "event_date(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 31, 2021 April 1, 2021\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "date = datetime.now()\n",
    "next_day = date + timedelta(days = 1)\n",
    "\n",
    "today = date.strftime(\"%B %-d, %Y\")\n",
    "tomorrow = next_day.strftime(\"%B %-d, %Y\")\n",
    "\n",
    "def next_some_days(num):\n",
    "    date_ = date + timedelta(days = num)\n",
    "    return date_.strftime(\"%B %-d, %Y\")\n",
    "\n",
    "print(today, tomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2021\n",
      "month: 03\n",
      "day: 31\n",
      "time: 08:37:02\n",
      "date and time: 03/31/2021, 08:37:02 AM\n",
      "2021-03-31 08:37:02.338861 love\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# now = datetime.fromtimestamp(1585892034661 / 1000.0)\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "year = now.strftime(\"%Y\")\n",
    "print(\"year:\", year)\n",
    "\n",
    "month = now.strftime(\"%m\")\n",
    "print(\"month:\", month)\n",
    "\n",
    "day = now.strftime(\"%d\")\n",
    "print(\"day:\", day)\n",
    "\n",
    "time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"time:\", time)\n",
    "\n",
    "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S %p\")\n",
    "print(\"date and time:\",date_time)\t\n",
    "\n",
    "print(datetime.today(), 'love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f33fbc400e034c3c9b28b473d62c215a-0\" class=\"displacy\" width=\"1070\" height=\"264.5\" direction=\"ltr\" style=\"max-width: none; height: 264.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"135\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"135\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"220\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"220\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"305\">play</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"305\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"390\">football.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"390\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"475\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"475\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"560\">hated</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"560\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"645\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"645\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"730\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"730\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"815\">my</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"815\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"900\">childhood</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"900\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"174.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"985\">though</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"985\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-0\" stroke-width=\"2px\" d=\"M70,129.5 C70,87.0 125.0,87.0 125.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,131.5 L62,119.5 78,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-1\" stroke-width=\"2px\" d=\"M240,129.5 C240,87.0 295.0,87.0 295.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M240,131.5 L232,119.5 248,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-2\" stroke-width=\"2px\" d=\"M155,129.5 C155,44.5 300.0,44.5 300.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M300.0,131.5 L308.0,119.5 292.0,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-3\" stroke-width=\"2px\" d=\"M325,129.5 C325,87.0 380.0,87.0 380.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M380.0,131.5 L388.0,119.5 372.0,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-4\" stroke-width=\"2px\" d=\"M495,129.5 C495,87.0 550.0,87.0 550.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495,131.5 L487,119.5 503,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-5\" stroke-width=\"2px\" d=\"M580,129.5 C580,87.0 635.0,87.0 635.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M635.0,131.5 L643.0,119.5 627.0,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-6\" stroke-width=\"2px\" d=\"M580,129.5 C580,44.5 725.0,44.5 725.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M725.0,131.5 L733.0,119.5 717.0,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-7\" stroke-width=\"2px\" d=\"M835,129.5 C835,87.0 890.0,87.0 890.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M835,131.5 L827,119.5 843,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-8\" stroke-width=\"2px\" d=\"M750,129.5 C750,44.5 895.0,44.5 895.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M895.0,131.5 L903.0,119.5 887.0,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f33fbc400e034c3c9b28b473d62c215a-0-9\" stroke-width=\"2px\" d=\"M580,129.5 C580,2.0 985.0,2.0 985.0,129.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f33fbc400e034c3c9b28b473d62c215a-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M985.0,131.5 L993.0,119.5 977.0,119.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "sen = sp(u\"I like to play football. I hated it in my childhood though\")\n",
    "displacy.render(sen, style='dep', jupyter=True, options={'distance': 85})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-96c2786ff3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmute_tf_warnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_mute_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflearn'"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from mute_tf_warnings import tf_mute_warning\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "tf_mute_warning()\n",
    "\n",
    "class ChatBot:\n",
    "        \n",
    "    \n",
    "    def data_mining(self):\n",
    "        data = dataset\n",
    "        words = [] # we tokenize all the patterns on our data\n",
    "        labels = [] # get all tags\n",
    "        docs_x = [] # pattern without being tokenize\n",
    "        docs_y = [] # labels for pattern without being tokenize\n",
    "\n",
    "\n",
    "        for tag in data:\n",
    "            for pattern in tag['pattern']:\n",
    "                wrds = word_tokenize(pattern)\n",
    "                words.extend(wrds)\n",
    "                docs_x.append(wrds)\n",
    "                docs_y.append(tag['tag'])\n",
    "\n",
    "            if tag['tag'] not in labels:\n",
    "                labels.append(tag['tag'])\n",
    "                \n",
    "        # Stemming and Remove Duplicates\n",
    "        words = [ stemmer.stem( word.lower() ) for word in words if word not in '?' and word not in '.']\n",
    "        words = list(dict.fromkeys(words))\n",
    "        labels = sorted(list(set(labels)))\n",
    "        \n",
    "        # Training Data\n",
    "        training = []\n",
    "        labels_for_training = []\n",
    "\n",
    "        for index, word in enumerate(docs_x):\n",
    "            temp = []\n",
    "            wrds = [stemmer.stem(w.lower()) for w in word] # loop through each pattern and stem the the word\n",
    "\n",
    "            for w in words: # comparing with our tokenize pattern\n",
    "                if w in wrds:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "\n",
    "            output_row = [ 0 for _ in range(len(labels)) ]\n",
    "            output_row[labels.index(docs_y[index])] = 1\n",
    "\n",
    "            training.append(temp)\n",
    "            labels_for_training.append(output_row)\n",
    "\n",
    "        training = np.array(training)\n",
    "        labels_for_training = np.array(labels_for_training)\n",
    "\n",
    "        return training, labels_for_training, words, labels\n",
    "    \n",
    "    def test_model(self, test_statement):\n",
    "        _,_,words,_ = self.data_mining()\n",
    "        bunch_of_words = [ 0 for _ in range(len(words))]\n",
    "        \n",
    "        test_input = word_tokenize(test_statement)\n",
    "        test_input = [ stemmer.stem(word.lower()) for word in test_input ]\n",
    "        \n",
    "        for test in test_input:\n",
    "            for index, word in enumerate(words):\n",
    "                if word == test:\n",
    "                    bunch_of_words[index] = 1\n",
    "                    \n",
    "        return np.array(bunch_of_words)\n",
    "        \n",
    "        \n",
    "    # Model\n",
    "    def model(self):\n",
    "        training, labels_for_training, _, _= self.data_mining()\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "        net = tflearn.fully_connected(net, 8)\n",
    "        net = tflearn.fully_connected(net, 8)\n",
    "        net = tflearn.fully_connected(net, len(labels_for_training[0]), activation=\"softmax\")\n",
    "        net = tflearn.regression(net)\n",
    "\n",
    "        model = tflearn.DNN(net)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test_and_train_model(self):\n",
    "        training, labels_for_training, _, labels = self.data_mining()\n",
    "        model = self.model()\n",
    "        \n",
    "        model.fit(training, labels_for_training, n_epoch=150,batch_size=6, show_metric=True)\n",
    "        \n",
    "        test_data = [ {\"tag\": tag['tag'], \"pattern\": tag['pattern'][0]} for tag in dataset ]\n",
    "        \n",
    "        for pattern in test_data:\n",
    "            tag = pattern['tag']\n",
    "            result = model.predict([self.test_model(pattern['pattern'])])\n",
    "            result_index = np.argmax(result)\n",
    "            result_tag = labels[result_index]\n",
    "\n",
    "            if tag == result_tag:\n",
    "                print(True,result_tag,':\\t',tag,)\n",
    "            else:\n",
    "                print(False, result_tag,':\\t',tag,':/t',pattern['pattern'])\n",
    "                self.test_and_train_model()\n",
    "                break\n",
    "        model.save('./saved models/model.tflearn')\n",
    "        \n",
    "    def user_input(self, user_text):\n",
    "        _, _, words, _ = self.data_mining()\n",
    "        word_que = [ 0 for _ in range(len(words))]\n",
    "\n",
    "        token_words = word_tokenize(user_text)\n",
    "        token_words = [ stemmer.stem( word.lower() ) for word in token_words ]\n",
    "\n",
    "        for word in token_words:\n",
    "            for index, data in enumerate(words):\n",
    "                if data == word:\n",
    "                    word_que[index] = 1\n",
    "        return np.array(word_que)\n",
    "\n",
    "\n",
    "    def talk(self, txt):\n",
    "        _,_,_, labels = self.data_mining()\n",
    "        model = self.model()\n",
    "        try:\n",
    "            model.load('./saved models/model.tflearn')\n",
    "            model_result = model.predict([self.user_input(txt)])\n",
    "            model_result_index = np.argmax(model_result)\n",
    "            \n",
    "            tag = labels[model_result_index]\n",
    "            \n",
    "            response = self.fetch_tag_and_response(tag)\n",
    "            \n",
    "            if model_result[0][model_result_index] >= 0.8:\n",
    "                res_tag = response['tag']\n",
    "                responses = response['responses']\n",
    "                \n",
    "                print(random.choice(responses))\n",
    "            else:\n",
    "                print('Try asking something else') # in case of this, it should deviate user from conversation and suggest new tags\n",
    "#             print(model_result[0][model_result_index], response['tag'])\n",
    "        except:\n",
    "            self.test_and_train_model()\n",
    "            sleep(3)\n",
    "            self.talk()\n",
    "            \n",
    "            \n",
    "    def test_me(self):\n",
    "        model = self.model()\n",
    "        _, _, _, labels = self.data_mining()\n",
    "        quest = False\n",
    "        database = []\n",
    "        try:\n",
    "            model.load('./saved models/model.tflearn')\n",
    "            print('Welcome \\n')\n",
    "            \n",
    "            while True:\n",
    "                user_text = input('You: ')\n",
    "                if user_text.lower() == 'stop':\n",
    "                    break\n",
    "                \n",
    "                if quest:\n",
    "                    database[0]['user_res'] = user_text\n",
    "#                     print(database)\n",
    "                    pos_, model_res = pos_tag(user_text)\n",
    "                    sleep(1)\n",
    "                    print(model_res)\n",
    "                    quest = False\n",
    "\n",
    "                else:\n",
    "                    result = model.predict([self.user_input(user_text)])[0]\n",
    "                    result_index = np.argmax(result)\n",
    "                    tag = labels[result_index]\n",
    "\n",
    "    #                 _tag = [ data for data in dataset if data['tag'] == tag]\n",
    "    #                 _res = _tag[0]['response']\n",
    "\n",
    "                    for data in dataset:\n",
    "                        if data['tag'] == tag:\n",
    "                            if len(data['response']) != 0 and data['state'] != True:\n",
    "                                _res = data['response'].pop()\n",
    "\n",
    "                                matcher_res = tag_matcher(_res)\n",
    "                                database.append(matcher_res)\n",
    "                                quest = True\n",
    "\n",
    "                                print(tag_matcher(_res),database)\n",
    "                                sleep(1)\n",
    "                                print('Bot: ',matcher_res['model_res'])\n",
    "\n",
    "                                break\n",
    "    #                 print(tag,'\\n',result)\n",
    "        except:\n",
    "            print('Save Model Not Found')\n",
    "            print('Initializing Traing and Testing \\n')\n",
    "#             self.test_and_train_model()\n",
    "#             sleep(3)\n",
    "             \n",
    "#             print('Training Successful')\n",
    "#             print('Initializing Chat')\n",
    "#             sleep(4)\n",
    "#             self.test_me()\n",
    "            \n",
    "new_bot = ChatBot()\n",
    "new_bot.test_and_train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_bot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0673a65d7a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_bot' is not defined"
     ]
    }
   ],
   "source": [
    "new_bot.test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_bot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0673a65d7a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_bot' is not defined"
     ]
    }
   ],
   "source": [
    "new_bot.test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bot.test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bot.test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bot.test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mute_tf_warnings\n",
      "Installing collected packages: mute-tf-warnings\n",
      "Successfully installed mute-tf-warnings-0.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mute_tf_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(filter_by:list, filter: list):\n",
    "    print(item= for item in filter_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "filter([1,2], [4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, username: str, id: int):\n",
    "        self.username = username\n",
    "        self.id = id\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_instance(obj: dict):\n",
    "        return User(**obj)\n",
    "    \n",
    "user = User.get_instance({\"username\": \"raymond\", \"id\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5d6143d37911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mhey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "def hey(a:list(dict)):\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
