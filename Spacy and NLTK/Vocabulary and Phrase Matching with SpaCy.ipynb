{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary and Phrase Matching with SpaCy\n",
    "<p>The spaCy library comes with Matcher tool that can be used to specify custom rules for phrase matching. The process to use the Matcher tool is pretty straight forward. The first thing you have to do is define the patterns that you want to match. Next, you have to add the patterns to the Matcher tool and finally, you have to apply the Matcher tool to the document that you want to match your rules with. This is best explained with the help of an example.<b>\n",
    "\n",
    "For rule-based matching, you need to perform the following steps:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "m_tool = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick likes to play football however he is not too fond of tennis\n"
     ]
    }
   ],
   "source": [
    "all_stopwords = list(set([\",\",\"!\",'\"','#','$','%','&','\\\\',\"'\",\"(\",\")\",'*','+','-','.','/',':',';','<','=','>','?','@','[',']','^','_','`','{','|','}','~',\"'\"]))\n",
    "\n",
    "text = \"Nick likes to play football, however he is not too fond of tennis. ?\"\n",
    "text_tokens = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
    "separator = \" \"\n",
    "\n",
    "print(separator.join(tokens_without_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to use Spacy Lemmatizer to get a word into basic form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -PRON- PRON\n",
      "need need VERB\n",
      "an an DET\n",
      "overview overview NOUN\n",
      "on on ADP\n",
      "invoice invoice NOUN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I need an overview on invoice\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Patterns\n",
    "<p>The next step is to define the patterns that will be used to filter similar phrases. Suppose we want to find the phrases \"quick-brown-fox\", \"quick brown fox\", \"quickbrownfox\" or \"quick brownfox\". To do so, we need to create the following four patterns:</p>\n",
    "\n",
    "- p1 looks for the phrase \"quickbrownfox\"\n",
    "- p2 looks for the phrase \"quick-brown-fox\"\n",
    "- p3 tries to search for \"qucik brown fox\"\n",
    "- p4 looks for the phrase \"quick brownfox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [{\"LOWER\": \"quickbrownfox\"}]\n",
    "p2 = [{'LOWER': 'quick'}, {'IS_PUNCT': True}, {'LOWER': 'brown'}, {'IS_PUNCT': True}, {'LOWER': 'fox'}]\n",
    "p3 = [{'LOWER': 'quick'}, {'LOWER': 'brown'}, {'LOWER': 'fox'}]\n",
    "p4 =  [{'LOWER': 'quick'}, {'LOWER': 'brownfox'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The token attribute LOWER defines that the phrase should be converted into lower case before matching.\n",
    "<br>\n",
    "Once the patterns are defined, we need to add them to the Matcher object that we created earlier.</p>\n",
    "<p>Here \"QBF\" is the name of our matcher. You can give it any name.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tool.add('QBF', None, p1, p2,p3,p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here \"QBF\" is the name of our matcher. You can give it any name.\n",
    "<p>We have our matcher ready. The next step is to apply the matcher on a text document and see if we can get any match. Let's first create a simple document:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nlp(u\"The quick-brown-fox jumps over the lazy dog. The quick brown fox eats well. The quickbrownfox is dead. The dog misses the quick brownfox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To apply the matcher to a document. The document is needed to be passed as a parameter to the matcher object. The result will be all the ids of the phrases matched in the document, along with their starting and ending positions in the document. Execute the following script:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12825528024649263697, 1, 6), (12825528024649263697, 13, 16), (12825528024649263697, 20, 21), (12825528024649263697, 28, 30)]\n"
     ]
    }
   ],
   "source": [
    "phrase_matches = m_tool(sentence)\n",
    "print(phrase_matches )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12825528024649263697 QBF 1 6 \t quick-brown-fox\n",
      "12825528024649263697 QBF 13 16 \t quick brown fox\n",
      "12825528024649263697 QBF 20 21 \t quickbrownfox\n",
      "12825528024649263697 QBF 28 30 \t quick brownfox\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in phrase_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = sentence[start:end]                   \n",
    "    print(match_id, string_id, start, end,'\\t', span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a simple pattern that can identify the phrase \"quick--brown--fox\" or quick-brown---fox.\n",
    "Let's first remove the previous matcher QBF.\n",
    "https://spacy.io/usage/linguistic-features#adding-patterns-attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12825528024649263697 QBF 1 6 quick--brown--fox\n",
      "12825528024649263697 QBF 10 15 quick-brown---fox\n"
     ]
    }
   ],
   "source": [
    "m_tool.remove('QBF')\n",
    "p1 = [{'LOWER': 'quick'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'brown'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'fox'}]\n",
    "m_tool.add('QBF', None, p1)\n",
    "sentence = nlp(u'The quick--brown--fox jumps over the  quick-brown---fox')\n",
    "phrase_matches = m_tool(sentence)\n",
    "\n",
    "for match_id, start, end in phrase_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  \n",
    "    span = sentence[start:end]                   \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase-Based Matching\n",
    "In the last section, we saw how we can define rules that can be used to identify phrases from the document. In addition to defining rules, we can directly specify the phrases that we are looking for.\n",
    "This is a more efficient way of phrase matching.\n",
    "\n",
    "In this section, we will be doing phrase matching inside a Wikipedia article on Artificial intelligence.\n",
    "\n",
    "Before we see the steps to perform phrase-matching, let's first parse the Wikipedia article that we will be using to perform phrase matching. Execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Phrase List\n",
    "In the second step, you need to create a list of phrases to match and then convert the list to spaCy NLP documents as shown in the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[machine learning, robots, intelligent agents]\n"
     ]
    }
   ],
   "source": [
    "phrases = ['machine learning', 'robots', 'intelligent agents']\n",
    "patterns = [ nlp(text) for text in phrases ]\n",
    "phrase_matcher.add('AI', None, *patterns)\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you need to add your phrase list to the phrase matcher.\n",
    "## Applying Matcher to the Document\n",
    "Like rule-based matching, we again need to apply our phrase matcher to the document. However, our parsed article is not in spaCy document format. Therefore, we will convert our article into sPacy document format and will then apply our phrase matcher to the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = \"In computer science, artificial intelligence(AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans. Leading AI textbooks define the field as the study of intelligent agents: any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.1 Colloquially, the term artificial intelligence is often used to describe machines(or computers) that mimic cognitive functions that humans associate with the human mind, such as learning and problem solving.2As machines become increasingly capable, tasks considered to require intelligence are often removed from the definition of AI, a phenomenon known as the AI effect.3 A quip in Tesler's Theorem says AI is whatever hasn't been done yet.4 For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.5 Modern machine capabilities generally classified as AI include successfully understanding human speech, 6 competing at the highest level in strategic game systems(such as chess and Go), 7 autonomously operating cars, intelligent routing in content delivery networks, and military simulations.Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, 89 followed by disappointment and the loss of funding(known as an AI winter), 1011 followed by new approaches, success and renewed funding.912 For most of its history, AI research has been divided into subfields that often fail to communicate with each other.13 These sub-fields are based on technical considerations, such as particular goals(e.g. robotics or machine learning), 14 the use of particular tools(logic or artificial neural networks), or deep philosophical differences.151617 Subfields have also been based on social factors(particular institutions or the work of particular researchers).13The traditional problems(or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.14 General intelligence is among the field's long-term goals.18 Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields.The field was founded on the assumption that human intelligence can be so precisely described that a machine can be made to simulate it.19 This raises philosophical arguments about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction and philosophy since antiquity.20 Some people also consider AI to be a danger to humanity if it progresses unabated.21, 22. Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.23In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understandingand AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_phrases = phrase_matcher(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ten', 'nobody', 'our', 'none', 'using', 'along', 'fifteen', 'except', 'forty', 'before', 'take', 'are', 'nine', 'while', 'often', 'whenever', 'after', 'his', 'top', 'twenty', 'hundred', 'anyway', 'anyhow', 'whither', 'here', 'done', 'indeed', 'various', 'already', \"'m\", 'between', 'four', 'against', 'ca', 'across', 'former', 'thereafter', 'fifty', 'which', 'seemed', 'him', 'perhaps', 'whereas', 'something', 'within', 'next', 'such', 'be', 'noone', 'they', 'name', 'both', 'give', 'made', 'us', 'somewhere', 'through', 'one', 'sometimes', 'really', 'yet', 'each', 'himself', 'together', 'their', 'few', 'regarding', 'whereupon', 'in', 'no', 'otherwise', 'sixty', 'third', 'two', 'my', 'down', 'these', 'n’t', 'thereupon', 'up', 'was', 'serious', 'most', 'some', 'how', 'an', 'latter', 'nor', 'around', 'being', 'everyone', 'for', 'is', 'unless', 'than', 'may', 'would', 'where', 'been', 'she', 'front', 'move', 'six', 'somehow', 'towards', 'bottom', 'go', 'did', 'since', 'twelve', 'becoming', 'wherein', 'below', 'have', 'me', 'anything', 'else', 'hers', 'were', 'your', 'i', \"n't\", 'doing', 'until', '’s', 'say', 'always', 'moreover', 'see', 'we', 'during', 'might', 'therefore', 'used', '‘d', 'must', 'make', 'only', 'side', 'a', 'everywhere', 'can', 'thereby', 'whoever', 're', 'beyond', 'quite', 'it', \"'ve\", 'call', 'enough', 'first', 'thus', 'on', 'nowhere', 'very', 'back', 'from', 'also', 'least', 'off', 'themselves', 'get', 'he', 'this', 'however', 'neither', 'ours', 'beside', 'anyone', 'do', 'everything', 'n‘t', 'that', 'over', 'onto', 'herself', 'beforehand', 'mostly', 'why', 'nothing', 'to', '’d', 'her', 'will', 'someone', 'yours', 'seems', 'who', 'hereupon', 'although', 'by', 'with', 'several', 'amongst', 'per', 'still', 'others', 'cannot', 'once', 'ourselves', 'without', 'whatever', 'much', '‘ll', '‘ve', 'sometime', 'them', 'whole', 'whose', 'eleven', 'either', 'full', 'five', 'almost', 'alone', 'had', 'throughout', 'empty', 'last', 'even', '’m', '‘re', 'just', 'latterly', 'seem', 'could', 'hence', 'at', 'elsewhere', '’re', 'every', 'about', 'another', 'whom', 'thence', 'as', 'upon', 'of', 'anywhere', 'then', 'never', 'whether', 'behind', 'those', 'wherever', 'has', 'more', 'other', '’ll', 'three', 'further', 'now', 'among', 'or', 'thru', 'what', 'whereafter', 'part', 'if', '‘m', 'its', 'and', 'seeming', 'because', 'does', 'less', 'rather', 'show', 'when', 'so', 'yourself', 'nevertheless', 'afterwards', 'many', 'but', 'hereafter', 'meanwhile', '’ve', 'out', 'keep', 'mine', 'myself', 'ever', 'eight', 'you', 'became', 'not', 'well', '‘s', 'own', 'am', 'amount', 'toward', 'into', 'again', \"'d\", 'due', 'though', 'therein', \"'s\", 'via', 'herein', 'above', 'become', 'namely', 'put', 'please', 'same', \"'ll\", 'hereby', 'yourselves', 'formerly', 'should', \"'re\", 'too', 'any', 'under', 'itself', 'whence', 'there', 'all', 'whereby', 'besides', 'becomes', 'the'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "print(sp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.vocab['wonder'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add or remove stopwords in spaCy, you can use sp.Defaults.stop_words.add() and sp.Defaults.stop_words.remove() methods respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.Defaults.stop_words.add('wonder')\n",
    "sp.vocab['wonder'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence = 'week revenue'\n",
    "search = re.search(r\"\"\"(?:last|past|ago|previous)\"\"\", sentence)\n",
    "is_past = search.group() if search else False\n",
    "print(is_past)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
